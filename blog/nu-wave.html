<!doctype html>
<html lang="en" dir="ltr">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width,initial-scale=1">
<meta name="generator" content="Docusaurus v2.0.0-beta.17">
<link rel="alternate" type="application/rss+xml" href="/blog/rss.xml" title="MINDsLab BRAIN Team RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/blog/atom.xml" title="MINDsLab BRAIN Team Atom Feed">
<link rel="preconnect" href="https://www.google-analytics.com">
<script>window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)},ga.l=+new Date,ga("create","UA-204903244-1","auto"),ga("set","anonymizeIp",!0),ga("send","pageview")</script>
<script async src="https://www.google-analytics.com/analytics.js"></script>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.24/dist/katex.min.css" integrity="sha384-odtC+0UGzzFL/6PNoE8rX/SPcQDXBJ+uRepguP4QkPCm2LBxH3FA3y+fKSiJ+AmM" crossorigin="anonymous"><title data-rh="true">NU-Wave(Interspeech): | MINDsLab BRAIN Team</title><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:url" content="https://mindslab-ai.github.io//blog/nu-wave"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docusaurus_tag" content="default"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docsearch:docusaurus_tag" content="default"><meta data-rh="true" property="og:title" content="NU-Wave(Interspeech): | MINDsLab BRAIN Team"><meta data-rh="true" name="description" content="ìµœì´ˆë¡œ 48kHzë¡œ upsamplingì„ ì„±ê³µí•œ ì €í¬ ì—°êµ¬ë¥¼ ì†Œê°œí•©ë‹ˆë‹¤."><meta data-rh="true" property="og:description" content="ìµœì´ˆë¡œ 48kHzë¡œ upsamplingì„ ì„±ê³µí•œ ì €í¬ ì—°êµ¬ë¥¼ ì†Œê°œí•©ë‹ˆë‹¤."><meta data-rh="true" property="og:image" content="https://mindslab-ai.github.io//img/mindslab_default.png"><meta data-rh="true" name="twitter:image" content="https://mindslab-ai.github.io//img/mindslab_default.png"><meta data-rh="true" property="og:type" content="article"><meta data-rh="true" property="article:published_time" content="2021-07-14T00:00:00.000Z"><meta data-rh="true" property="article:author" content="https://github.com/junjun3518,https://github.com/Seungwoo0326"><meta data-rh="true" property="article:tag" content="publication,paper-review"><link data-rh="true" rel="icon" href="/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://mindslab-ai.github.io//blog/nu-wave"><link data-rh="true" rel="alternate" href="https://mindslab-ai.github.io//blog/nu-wave" hreflang="en"><link data-rh="true" rel="alternate" href="https://mindslab-ai.github.io//blog/nu-wave" hreflang="x-default"><link rel="stylesheet" href="/assets/css/styles.def04243.css">
<link rel="preload" href="/assets/js/runtime~main.42946587.js" as="script">
<link rel="preload" href="/assets/js/main.cca28c97.js" as="script">
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){var t=null;try{t=localStorage.getItem("theme")}catch(t){}return t}();t(null!==e?e:"light")}()</script><div id="__docusaurus">
<div role="region"><a href="#" class="skipToContent_ZgBM">Skip to main content</a></div><nav class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Navigation bar toggle" class="navbar__toggle clean-btn" type="button" tabindex="0"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/mindslab_brain.svg" alt="MINDsLab BRAIN Team" class="themedImage_W2Cr themedImage--light_TfLj"><img src="/img/mindslab_brain.svg" alt="MINDsLab BRAIN Team" class="themedImage_W2Cr themedImage--dark_oUvU"></div><b class="navbar__title"></b></a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/blog">Blog</a><a class="navbar__item navbar__link" href="/publications">Publications</a><a class="navbar__item navbar__link" href="/open-source">Open-Source</a></div><div class="navbar__items navbar__items--right"><a class="navbar__item navbar__link" href="/careers">Careers</a><a href="https://github.com/mindslab-ai" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link"><span>GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_I5OW"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></span></a><div class="toggle_S7eR toggle_TdHA toggleDisabled_f9M3"><div class="toggleButton_rCf9" role="button" tabindex="-1"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_v35p"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_nQuB"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></div><input type="checkbox" class="toggleScreenReader_g2nN" aria-label="Switch between dark and light mode (currently light mode)"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div class="main-wrapper blog-wrapper blog-post-page"><div class="container margin-vert--lg"><div class="row"><aside class="col col--3"><nav class="sidebar_a9qW thin-scrollbar" aria-label="Blog recent posts navigation"><div class="sidebarItemTitle_uKok margin-bottom--md">All posts</div><ul class="sidebarItemList_Kvuv"><li class="sidebarItem_CF0Q"><a class="sidebarItemLink_miNk" href="/blog/nu-wave2">NU-Wave 2: A General Neural Audio Upsampling Model for Various Sampling Rates</a></li><li class="sidebarItem_CF0Q"><a class="sidebarItemLink_miNk" href="/blog/sane-tts">SANE-TTS: Stable And Natural End-to-End Multilingual Text-to-Speech</a></li><li class="sidebarItem_CF0Q"><a class="sidebarItemLink_miNk" href="/blog/assem-vc">Assem-VC and Assem-Singer:</a></li><li class="sidebarItem_CF0Q"><a class="sidebarItemLink_miNk" href="/blog/ces-2022-review">CES 2022ì— ì°¸ì„í•œ ë§ˆì¸ì¦ˆë©, AI Human</a></li><li class="sidebarItem_CF0Q"><a class="sidebarItemLink_miNk" href="/blog/vits">VITS: Conditional Variational Autoencoder with Adversarial Learning for End-to-End Text-to-Speech</a></li><li class="sidebarItem_CF0Q"><a class="sidebarItemLink_miNk" href="/blog/acon">Activate or Not: Learning Customized Activation</a></li><li class="sidebarItem_CF0Q"><a aria-current="page" class="sidebarItemLink_miNk sidebarItemLinkActive_RRTD" href="/blog/nu-wave">NU-Wave(Interspeech):</a></li></ul></nav></aside><main class="col col--7" itemscope="" itemtype="http://schema.org/Blog"><article itemprop="blogPost" itemscope="" itemtype="http://schema.org/BlogPosting"><header><h1 class="blogPostTitle_rzP5" itemprop="headline">NU-Wave(Interspeech):</h1><div class="blogPostData_Zg1s margin-vert--md"><time datetime="2021-07-14T00:00:00.000Z" itemprop="datePublished">July 14, 2021</time> Â· <!-- -->16 min read</div><div class="margin-top--md margin-bottom--sm row"><div class="col col--6 authorCol_FlmR"><div class="avatar margin-bottom--sm"><span class="avatar__photo-link avatar__photo"><a href="https://github.com/junjun3518" target="_blank" rel="noopener noreferrer"><img class="image_o0gy" src="https://github.com/junjun3518.png" alt="Junhyeok Lee"></a></span><div class="avatar__intro" itemprop="author" itemscope="" itemtype="https://schema.org/Person"><div class="avatar__name"><a href="https://github.com/junjun3518" target="_blank" rel="noopener noreferrer" itemprop="url"><span itemprop="name">Junhyeok Lee</span></a></div><small class="avatar__subtitle" itemprop="description">AI Scientist (Audio, Head)</small></div></div></div><div class="col col--6 authorCol_FlmR"><div class="avatar margin-bottom--sm"><span class="avatar__photo-link avatar__photo"><a href="https://github.com/Seungwoo0326" target="_blank" rel="noopener noreferrer"><img class="image_o0gy" src="https://github.com/Seungwoo0326.png" alt="Seungu Han"></a></span><div class="avatar__intro" itemprop="author" itemscope="" itemtype="https://schema.org/Person"><div class="avatar__name"><a href="https://github.com/Seungwoo0326" target="_blank" rel="noopener noreferrer" itemprop="url"><span itemprop="name">Seungu Han</span></a></div><small class="avatar__subtitle" itemprop="description">AI Scientist (Audio)</small></div></div></div></div></header><meta itemprop="image" content="https://mindslab-ai.github.io//img/mindslab_default.png"><div id="post-content" class="markdown" itemprop="articleBody"><p><a href="https://arxiv.org/abs/2104.02321" target="_blank" rel="noopener noreferrer"><img src="https://img.shields.io/badge/arXiv-2104.02321-brightgreen.svg?style=flat-square" alt="arXiv"></a> <a href="https://github.com/mindslab-ai/nuwave" target="_blank" rel="noopener noreferrer"><img src="https://img.shields.io/github/stars/mindslab-ai/nuwave?color=yellow&amp;label=NU-Wave&amp;logo=github&amp;style=flat-square" alt="GitHub Repo stars"></a> <a href="https://mindslab-ai.github.io/nuwave/" target="_blank" rel="noopener noreferrer"><img src="https://img.shields.io/badge/GitHub.io-audio_samples-blue?logo=Github&amp;style=flat-square" alt="githubio"></a></p><h2 class="anchor anchorWithStickyNavbar_mojV" id="a-diffusion-probabilistic-model-for-neural-audio-upsampling">A Diffusion Probabilistic Model for Neural Audio Upsampling<a class="hash-link" href="#a-diffusion-probabilistic-model-for-neural-audio-upsampling" title="Direct link to heading">â€‹</a></h2><p>ì•ˆë…•í•˜ì„¸ìš” MINDs Lab Brainì—ì„œ Audioì™€ Speech ì—°êµ¬ë¥¼ í•˜ê³  ìˆëŠ” <a href="https://github.com/junjun3518" target="_blank" rel="noopener noreferrer">ì´ì¤€í˜</a>ì…ë‹ˆë‹¤. Audio domainì˜ ë”¥ëŸ¬ë‹ ì—°êµ¬ëŠ” ëŒ€ë¶€ë¶„ <em>Sampling Rate</em> 16kHzì¸ ê²½ìš°ì— ëŒ€í•´ì„œ ì§„í–‰ë˜ì—ˆìŠµë‹ˆë‹¤. ìƒì„±ëª¨ë¸ (TTS) ê°™ì€ ê²½ìš° 22.05kHzì¸ ê²½ìš°ë„ ìˆì—ˆì§€ë§Œ ìŒì•…ì´ë‚˜ ì˜í™” ìª½ì—ì„œ ë§ì´ ì“°ì´ëŠ” 44.1kHzë‚˜ 48kHzì— ë¹„í•´ì„œëŠ” ì ˆë°˜ë°–ì— ì•ˆ ë˜ëŠ” sampling rateì´ì—ˆê¸° ë•Œë¬¸ì— high sampling rate TTSì— ëŒ€í•œ ìˆ˜ìš”ê°€ ê¾¸ì¤€íˆ ìˆì—ˆìŠµë‹ˆë‹¤. ì €í¬ê°€ ê°œë°œí•œ TTSì— ëŒ€í•´ì„œ ë” ë†’ì€ í€„ë¦¬í‹°ë¡œ ì„œë¹„ìŠ¤ë¥¼ ì œê³µí•˜ê¸° ìœ„í•´ì„œ <em>Neural Audio Upsampling</em>ì— ëŒ€í•œ ì—°êµ¬ë¥¼ ì§„í–‰í•˜ê²Œ ë˜ì—ˆìŠµë‹ˆë‹¤. 48kHzë¼ëŠ” ë†’ì€ sampling rateë¥¼ ëª©í‘œë¡œ í•˜ëŠ” ì—°êµ¬ë¥¼ ì§„í–‰í•˜ë‹¤ ë³´ë‹ˆ ìì—°ìŠ¤ëŸ½ê²Œ ìµœê·¼ì— í•«í•œ ìƒì„±ëª¨ë¸ì¸ <em>diffusion model</em>ì„ ì ìš©í•˜ê²Œ ë˜ì—ˆê³  <strong>ìµœì´ˆë¡œ 48kHzë¥¼ targetìœ¼ë¡œ upsampling í•˜ëŠ”ë° ì„±ê³µ</strong>í•˜ì˜€ìŠµë‹ˆë‹¤. ì´ë ‡ê²Œ ì§„í–‰í•œ ì—°êµ¬ë¡œ <a href="https://github.com/Seungwoo0326" target="_blank" rel="noopener noreferrer">ìŠ¹ìš°</a>ë‹˜ê³¼ ê°™ì´ ì“´ paperê°€ <strong>ì„¸ê³„ ìµœê³ ì˜ ìŒì„±ì‹ í˜¸ì²˜ë¦¬í•™íšŒì¸ <a href="https://www.interspeech2021.org" target="_blank" rel="noopener noreferrer">INTERSPEECH 2021</a>ì— Accept</strong>ğŸ‰ ë˜ì–´ ì†Œê°œí•´ ë“œë¦¬ê³ ì í•©ë‹ˆë‹¤!</p><h3 class="anchor anchorWithStickyNavbar_mojV" id="audio-upsampling">Audio Upsampling<a class="hash-link" href="#audio-upsampling" title="Direct link to heading">â€‹</a></h3><p>Image domainì—ì„œì˜ super resolutionì— í•´ë‹¹í•˜ëŠ” ë¶„ì•¼ê°€ <em>Audio Upsampling</em>ì…ë‹ˆë‹¤. Image super resolutionì—ì„œ ë”°ì™€ì„œ <em>audio super resolution</em> í˜¹ì€ ì£¼íŒŒìˆ˜ ë²”ìœ„ (bandwidth)ë¥¼ ë„“íŒë‹¤ëŠ” ì˜ë¯¸ë¡œ <em>bandwidth extension</em>ì´ë¼ê³  ë¶€ë¥´ê¸°ë„ í•©ë‹ˆë‹¤. Audioì˜ ê²½ìš° 1ì´ˆì— ëª‡ ë²ˆ samplingì„ í•˜ëŠ”ì§€ë¥¼ ë‚˜íƒ€ë‚´ëŠ” <em>Sampling Rate</em>ë¡œ temporal resolutionì„ í‘œí˜„í•©ë‹ˆë‹¤. ì´ ê°’ì´ ì¤‘ìš”í•œ ì´ìœ ëŠ” sampling rateê°€ ì •í•´ì§€ë©´ discrete-time (or digital) audio dataê°€ ê°€ì§ˆ ìˆ˜ ìˆëŠ” maximum frequency (Nyquist frequency)ê°€ ì •í•´ì§€ê¸° ë•Œë¬¸ì¸ë°ìš”. Audio domainì— ìµìˆ™í•˜ì§€ ì•Šìœ¼ì‹  ê²½ìš° ì•„ë˜ ê·¸ë¦¼ì„ ë³´ì‹œë©´ ì´í•´ê°€ ë¹ ë¥´ì‹¤ ê²ƒ ê°™ìŠµë‹ˆë‹¤.</p><ul><li>continuous-time ë°ì´í„° <img loading="lazy" alt="ì–´ë–¤ audio data" src="/assets/images/sine-9ec2c96c851cc3e7dcc1e7a578ef524d.png" width="1660" height="314"></li><li>1000Hzë¡œ ìƒ˜í”Œë§ í–ˆì„ ë•Œ  <img loading="lazy" alt="1000Hzë¡œ ìƒ˜í”Œë§ í–ˆì„ë•Œ" src="/assets/images/sr1000hz-58acc22915ef3d61f1c1311f8c41da6e.png" width="1502" height="337"></li><li>100Hzë¡œ ìƒ˜í”Œë§ í–ˆì„ ë•Œ <img loading="lazy" alt="100Hz ë¡œ ìƒ˜í”Œë§ í–ˆì„ë•Œ" src="/assets/images/sr100hz-9ba2eaaa9681cfa08ca797e6677f8e72.png" width="1720" height="289"></li></ul><p>ê³µê¸°ì˜ ì§„ë™ì— í•´ë‹¹í•˜ëŠ” ì†Œë¦¬ë¥¼ audio dataë¡œ ì»´í“¨í„°ì—ì„œ ë‹¤ë£¨ê¸° ìœ„í•´ì„œëŠ” ë§ˆì´í¬ì—ì„œ ìˆ˜ìŒëœ ì‹ í˜¸ë¥¼ discretizeí•˜ëŠ” ê³¼ì •ì´ í•„ìš”í•œë°, ì‹œê°„ì— ëŒ€í•´ discretize í•˜ëŠ” ê²ƒì„ samplingì´ë¼ê³  í•©ë‹ˆë‹¤. ì›ë³¸ ì‹ í˜¸ë³´ë‹¤ sampling rateê°€ ìƒë‹¹íˆ ë†’ì„ ê²½ìš° ë‘ ë²ˆì§¸ ê·¸ë¦¼ì²˜ëŸ¼ ì‹ í˜¸ì— ëŒ€í•œ ì •ë³´ë¥¼ ì˜ ë‹´ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. í•˜ì§€ë§Œ ì´ ê³¼ì •ì—ì„œ ì‹ í˜¸ì˜ ì£¼íŒŒìˆ˜ê°€ <em>N</em>ì¼ ë•Œ sampling rateê°€ 2<!-- -->*<em>N</em> ë³´ë‹¤ ì‘ë‹¤ë©´ ì‹ í˜¸ì— ëŒ€í•œ ì–´ë–¤ ì •ë³´ë„ ì–»ì„ ìˆ˜ ì—†ëŠ” ë…¸ì´ì¦ˆê°€ ë˜ê²Œ ë©ë‹ˆë‹¤. ìœ„ì˜ ì‚¬ì§„ì—ì„œ ì„¸ ë²ˆì§¸ ê·¸ë¦¼ì´ ê·¸ ì¼€ì´ìŠ¤ì£ . 2<!-- -->*<em>N</em>ì¸ ê²½ìš° ìš´ì´ ì¢‹ë‹¤ë©´ ì£¼íŒŒìˆ˜ <em>N</em>ìœ¼ë¡œ ì§„ë™í•˜ëŠ” ì‹ í˜¸ê°€ ìˆë‹¤ ì •ë„ëŠ” ì•Œì•„ë‚¼ ìˆ˜ ìˆê²Œ ë©ë‹ˆë‹¤. </p><p>ì–´ë–¤ ì‹ í˜¸ë¥¼ ë”¥ëŸ¬ë‹ ì—†ì´ linear, nearest interpolation ë“±ì˜ ë°©ë²•ìœ¼ë¡œ upsamplingí•˜ê²Œë˜ë©´ ìœ„ì˜ ì´ìœ  ë•Œë¬¸ì— ì›ë³¸ì˜ sampling rateì˜ ì ˆë°˜ ì´ìƒì— í•´ë‹¹í•˜ëŠ” ì£¼íŒŒìˆ˜ëŠ” í¬í•¨í•˜ì§€ ì•Šê²Œ ë©ë‹ˆë‹¤ <del>ì •í™•íˆëŠ” spectral aliasê°€ ìƒê¸°ê¸° ë•Œë¬¸ì— post filteringì„ í•˜ê¸° ë•Œë¬¸ì´ì§€ë§Œ ì‹ í˜¸ì²˜ë¦¬ ì‹œê°„ì´ ì•„ë‹ˆë‹ˆ ë„˜ì–´ê°€ì£ </del>. ê·¸ë˜ì„œ sampling rate ìì²´ëŠ” ë†’ì•„ì§€ì§€ë§Œ STFT (Short-Time Fourier Transform)ì„ í–ˆì„ ë•Œ ìœ—ë¶€ë¶„ì´ ë¹„ì–´ ë³´ì´ê²Œ ë©ë‹ˆë‹¤. ì´ëŸ° ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ì„œ ë”¥ëŸ¬ë‹ì„ ì ìš©í•œ ì—°êµ¬ë“¤ì´ ìˆìŠµë‹ˆë‹¤. í¬ê²Œ ì €í¬ ì—°êµ¬ì™€ ë¹„êµí•œ ì¼€ì´ìŠ¤ ë‘ ê°œë§Œ ì†Œê°œí•˜ê³  ë„˜ì–´ê°€ê² ìŠµë‹ˆë‹¤.</p><h4 class="anchor anchorWithStickyNavbar_mojV" id="audio-super-resolution-using-neural-networkssup1sup">Audio Super Resolution Using Neural Networks<a href="#r1"><sup>[1]</sup></a><a class="hash-link" href="#audio-super-resolution-using-neural-networkssup1sup" title="Direct link to heading">â€‹</a></h4><img class="figCenter_mKJ5" src="/assets/images/keenet-baf3f0ed9e6e3dec155b5823f711a6b2.png" alt="keenet"><p>Audio upsampling taskì—ì„œ ë”¥ëŸ¬ë‹ì„ ì ìš©í•œ ì²« ë…¼ë¬¸ì…ë‹ˆë‹¤. U-Netê³¼ ê°™ì€ êµ¬ì¡°ë¥¼ ì ìš©í•˜ì˜€ê³  <em>N</em> Hz ì‹ í˜¸ë¥¼ inputìœ¼ë¡œ í•˜ê³  <em>N<!-- -->*<!-- -->r</em> Hz ì‹ í˜¸ë¥¼ outputìœ¼ë¡œ í•˜ëŠ” ëª¨ë¸ì…ë‹ˆë‹¤. Lossë¡œ L<sub>2</sub>-normì„ ì‚¬ìš©í•˜ì˜€ìŠµë‹ˆë‹¤.</p><h4 class="anchor anchorWithStickyNavbar_mojV" id="bandwidth-extension-on-raw-audio-via-generative-adversarial-networkssup2sup">Bandwidth Extension on Raw Audio via Generative Adversarial Networks<a href="#r2"><sup>[2]</sup></a><a class="hash-link" href="#bandwidth-extension-on-raw-audio-via-generative-adversarial-networkssup2sup" title="Direct link to heading">â€‹</a></h4><img class="figCenter_mKJ5" src="/assets/images/mugan-3aeb03015f7ec5cc1219d1aa99e1c1c0.png" alt="mugan"><p>GANì„ ì‚¬ìš©í•´ì„œ upsamplingì„ ì‹œë„í•œ ë…¼ë¬¸ì…ë‹ˆë‹¤. êµ¬ì¡° ìì²´ëŠ” ìœ„ì˜ ë…¼ë¬¸ê³¼ ë¹„ìŠ·í•˜ê³  lossë¡œ L<sub>2</sub>-norm, discriminator loss, feature lossë¥¼ ì‚¬ìš©í•˜ì˜€ìŠµë‹ˆë‹¤.</p><h3 class="anchor anchorWithStickyNavbar_mojV" id="diffusion-probabilistic-models">Diffusion Probabilistic Models<a class="hash-link" href="#diffusion-probabilistic-models" title="Direct link to heading">â€‹</a></h3><h4 class="anchor anchorWithStickyNavbar_mojV" id="what-is-diffusion-model">What is Diffusion Model?<a class="hash-link" href="#what-is-diffusion-model" title="Direct link to heading">â€‹</a></h4><p>ìµœê·¼ <em>Denoising Diffusion Probabilistic Model</em><a href="#r3"><sup>[3]</sup></a>ì„ í•„ë‘ë¡œ <em>diffusion probabilistic model</em> (ì¤„ì—¬ì„œ <em>diffusion model</em>)ì´ í•«í•œ ìƒì„±ëª¨ë¸ë¡œ ë– ì˜¤ë¥´ê³  ìˆìŠµë‹ˆë‹¤. ë” ë„“ì€ ë²”ìœ„ì˜ <em>score-based model</em>ì´ë¼ëŠ” ê²ƒë„ ìˆìœ¼ë‚˜ ì´ ì¹œêµ¬ëŠ” ì•„ë§ˆ ë‹¤ë¥¸ í¬ìŠ¤íŠ¸ë¡œ ì†Œê°œí•  ê²ƒ ê°™ìŠµë‹ˆë‹¤. Diffusion modelì€ GANì´ë‚˜ VAEì™€ ë‹¤ë¥´ê²Œ outputê³¼ latent variableì˜ ì‚¬ì´ì¦ˆê°€ ê°™ìŠµë‹ˆë‹¤. latent varableì€ ê° step ë§ˆë‹¤ ì›ë³¸ì— ì¼ì •í•œ Gaussian noiseê°€ ë”í•´ì§„ ê²ƒìœ¼ë¡œ ì •ì˜ë©ë‹ˆë‹¤. ì´ë¥¼ 0ë¶€í„° Tê¹Œì§€ì˜ stepì„ ê°€ì§€ê³  <em>forward/reverse</em> ë‘ ê°œì˜ pathë¥¼ ê°€ì§€ëŠ” Markov chainìœ¼ë¡œ ìƒê°í•©ë‹ˆë‹¤. Forward pathì˜ ê²½ìš° ìœ„ì—ì„œ ì„¤ëª…í•œëŒ€ë¡œ ê·¸ ì „ stepì—  Gaussian noiseë¥¼ ë”í•˜ëŠ” ê²ƒìœ¼ë¡œ ì •ì˜ë˜ê³  reverse path ì˜ ê²½ìš° forward pathì—ì„œ ë”í•´ì§„ Gaussian noiseë¥¼ ì˜ˆì¸¡í•´ì„œ ë¹¼ëŠ” ê²ƒìœ¼ë¡œ ì •ì˜ë©ë‹ˆë‹¤. ê²°ê³¼ì ìœ¼ë¡œ Gaussian distributionìœ¼ë¡œë¶€í„° samplingí•œ latent variableì„ ì—¬ëŸ¬ ë²ˆ iterationì„ í•˜ëŠ” Markov Chain Monte-Carlo Samplingì„ í†µí•´ noiseë¥¼ ì œê±°í•´ê°€ë©´ì„œ ìš°ë¦¬ê°€ ì›í•˜ëŠ” outputìœ¼ë¡œ samplingí•˜ëŠ” ëª¨ë¸ì…ë‹ˆë‹¤. </p><img class="figCenter_mKJ5" src="/assets/images/mc-5f6f8ce73ca2b806164c34b56a69fa7d.png" alt="ì›ë˜_ë…¼ë¬¸ì—_ë„£ìœ¼ë ¤ê³ _í–ˆë˜_ì´ë¯¸ì§€"><p><em>ì›ë˜ ë…¼ë¬¸ì— ë„£ê³  ì‹¶ì—ˆëŠ”ë° 4pë¼ ë¶„ëŸ‰ì´ ëª¨ìë¼ ëª» ë„£ì€ Markov Chain ì´ë¯¸ì§€. forward path(ì ì„ ), reverse path(ì§ì„ )</em></p><h4 class="anchor anchorWithStickyNavbar_mojV" id="training-and-sampling">Training and Sampling<a class="hash-link" href="#training-and-sampling" title="Direct link to heading">â€‹</a></h4><p>ì›ë³¸ ë°ì´í„°ì— ì„ì˜ë¡œ ë…¸ì´ì¦ˆë¥¼ ë”í•˜ê³  ë”í•´ì§„ ë…¸ì´ì¦ˆë¥¼ ëª¨ë¸ì´ ì˜ˆì¸¡í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ í•™ìŠµì„ ì§„í–‰í•˜ê³  samplingì‹œì—ëŠ” Gaussian noiseë¶€í„° ì‹œì‘í•˜ì—¬ ìš°ë¦¬ê°€ ì›í•˜ëŠ” data distributionìœ¼ë¡œ ê°€ëŠ” ë°©í–¥ì— í•´ë‹¹í•˜ëŠ” noise (score)ë¥¼ ì˜ˆì¸¡í•˜ì—¬ ë¹¼ì£¼ëŠ” ê²ƒì„ ë°˜ë³µí•˜ê²Œ ë©ë‹ˆë‹¤. Diffusion modelì€ samplingì´ ì—¬ëŸ¬ ë²ˆ ë°˜ë³µë˜ì–´ì•¼ í•˜ê¸° ë•Œë¬¸ì— ì˜¤ë˜ ê±¸ë¦°ë‹¤ëŠ” ë‹¨ì ì´ ìˆì§€ë§Œ ë§¤ìš° ë†’ì€ í€„ë¦¬í‹°ì˜ sampleì„ ìƒì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.</p><img class="figCenter_mKJ5" src="/assets/images/ddpm-85c710f98f04d34f5743f5e6d2ae5e6f.png" alt="ddpm"><p><em>DDPMì˜ training and sampling algoritihm</em></p><h4 class="anchor anchorWithStickyNavbar_mojV" id="conditional-diffusion-models-as-a-neural-vocoder">Conditional Diffusion Models as a Neural Vocoder<a class="hash-link" href="#conditional-diffusion-models-as-a-neural-vocoder" title="Direct link to heading">â€‹</a></h4><table><thead><tr><th>DiffWave Architecture</th><th>WaveGrad Architecture</th></tr></thead><tbody><tr><td><img loading="lazy" alt="DiffWave" src="/assets/images/diffwave-6da070936ba7db2f9ed945027935b669.png" width="1292" height="922"></td><td><img loading="lazy" alt="wavegrad" src="/assets/images/wavegrad-f28ddfc7bbfa30ea46fffdcd505021c0.png" width="1170" height="1190"></td></tr></tbody></table><p>Diffusion modelì´ audio domainì— ê°€ì¥ ë¨¼ì € ì ìš©ëœ ë¶„ì•¼ëŠ” neural vocoderì¸ë°ìš”, neural vocoderëŠ” Mel<!-- -->-<!-- -->spectrogramì„ inputìœ¼ë¡œ ë°›ì•„ raw audioë¥¼ ìƒì„±í•˜ëŠ” ëª¨ë¸ì…ë‹ˆë‹¤. <em>ICLR 2020</em>ì— ë™ì‹œì— <em>DiffWave</em><a href="#r4"><sup>[4]</sup></a>ì™€ <em>WaveGrad</em><a href="#r5"><sup>[5]</sup></a>ë¼ëŠ” diffusion-based neural vocoder ë…¼ë¬¸ì´ ë‚˜ì™”ìŠµë‹ˆë‹¤. Mel-spectrogramì„ local conditionìœ¼ë¡œ ì£¼ê³   ë§ˆì°¬ê°€ì§€ë¡œ noiseë¡œë¶€í„° iterativeí•˜ê²Œ sampling í•©ë‹ˆë‹¤. Mel-spectrogramê³¼ outputì¸ raw waveformì´ linearí•˜ê²Œ align ë˜ì–´ ìˆë‹¤ëŠ” ì ì€ audio upsamplingê³¼ ìœ ì‚¬í•˜ì—¬ ì ê·¹ì ìœ¼ë¡œ audio upsampling ì—°êµ¬ì— ì°¨ìš©í•˜ì˜€ìŠµë‹ˆë‹¤. </p><p>ì‚¬ì‹¤ ì´ ì—°êµ¬ëŠ” ìœ„ì˜ ë…¼ë¬¸ë“¤ì„ ì½ê³  ë„ˆë¬´ ê°ëª… ë°›ì•„<del>ê°„ì§€ë‚˜ì„œ</del> ì‹œì‘í•˜ê²Œ ë˜ì—ˆìŠµë‹ˆë‹¤.</p><h3 class="anchor anchorWithStickyNavbar_mojV" id="nu-wave">NU-Wave<a class="hash-link" href="#nu-wave" title="Direct link to heading">â€‹</a></h3><p>ì²˜ìŒì—” ëª©í‘œë¥¼ <strong>48kHzë¥¼ íƒ€ê²Ÿìœ¼ë¡œ í•˜ëŠ” neural audio upsamplingì„ í•˜ëŠ” ê²ƒ</strong>ìœ¼ë¡œ ì¡ì•˜ìŠµë‹ˆë‹¤. ê·¸ë¦¬ê³  êµ¬í˜„ì´ ìƒëŒ€ì ìœ¼ë¡œ ê°„ë‹¨í•œ ìœ„ì— ì†Œê°œí–ˆì—ˆë˜ ì—°êµ¬ë“¤ì„ êµ¬í˜„í•˜ì—¬ ì§„í–‰í•˜ì˜€ìŠµë‹ˆë‹¤. ê·¸ëŸ°ë° ìƒìƒ ì´ìƒìœ¼ë¡œ ê²°ê³¼ê°€ ì¢‹ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. Low frequency ë¶€ë¶„ì€ í¬ê²Œ ê±´ë“œë¦¬ì§€ ì•Šì•˜ì§€ë§Œ high frequency ë¶€ë¶„ë“¤ì€ ë„ˆë¬´ ê³¼í•˜ê±°ë‚˜ ê±°ì˜ ì—†ê±°ë‚˜ í–ˆìŠµë‹ˆë‹¤. ê·¸ëŸ¬ë˜ ì¤‘ ìœ„ì—ì„œ ì„¤ëª…í•œ <em>diffusion model</em>ì´ vocoder taskì—ì„œ ì¢‹ì€ ê²°ê³¼ë¥¼ ë‚´ì—ˆê³  image domainì—ì„œë„ 1024x1024 í•´ìƒë„ì˜ ì´ë¯¸ì§€ë¥¼ samplingí•œ ê²°ê³¼ê°€ ìˆì–´ ë°”ë¡œ ì ìš©í•´ ë³´ê¸°ë¡œ í•˜ì˜€ìŠµë‹ˆë‹¤. </p><img class="figCenter_mKJ5" src="/assets/images/nuwave-b0ed027091ad1432d7bb68564a7816b8.png" alt="nuwave"><p><em>NU-Waveì˜ architectureì™€ algorithm</em></p><p>Neural vocoder ì—°êµ¬ë¥¼ audio upsamplingì— ì ìš©í•˜ê¸° ìœ„í•´ DiffWaveì™€ WaveGradë¥¼ ë§ì´ ì°¸ê³ í–ˆìŠµë‹ˆë‹¤. êµ¬ì¡°ëŠ” dilation convolutionì„ ì‚¬ìš©í•œ DiffWaveì˜ êµ¬ì¡°ê°€ U-Net likeí•œ WaveGrad ë³´ë‹¤ ì‚¬ì´ì¦ˆì— ë” ì¼ë°˜ì ì¼ ê²ƒìœ¼ë¡œ ìƒê°í•˜ì—¬ DIffWaveì˜ êµ¬ì¡°ì™€ ìµœëŒ€í•œ ìœ ì‚¬í•˜ê²Œ ë§Œë“¤ì—ˆê³ , WaveGradì˜ ê²½ìš° training ê³¼ì •ì—ì„œ continuous noise level trainingì´ë¼ëŠ” ê²ƒì„ ì ìš©í•˜ì—¬ samplingì‹œì— ë” ì ì€ ìˆ˜ì˜ iterationìœ¼ë¡œ samplingì„ í•˜ëŠ” ë°©ë²•ì„ ì°¸ê³ í•˜ì˜€ìŠµë‹ˆë‹¤. </p><p>Neural vocoderì—ì„œ ì‚¬ìš©ëœ ê°’ë“¤ì„ upsamplingì— ì‚¬ìš©í•˜ë ¤ê³  í•˜ë‹¤ ë³´ë‹ˆ ëª‡ê°€ì§€ ë¬¸ì œì ì´ ìˆì—ˆìŠµë‹ˆë‹¤.</p><ol><li>Raw waveformì„ conditionìœ¼ë¡œ ë„£ì–´ì¤¬ì„ ë•Œ receptive fieldê°€ ë„ˆë¬´ ì‘ì•„ conditionì´ ë³„ë¡œ ì˜í–¥ì„ ì£¼ì§€ ëª»í–ˆë‹¤.</li><li>ìƒê°ë³´ë‹¤ sampleì´ ë§ì´ noisy í•˜ë‹¤.</li><li>ë„ˆë¬´ high sampling rateë¥¼ targetìœ¼ë¡œ í•˜ë‹¤ ë³´ë‹ˆ computing powerê°€ ë§ì´ í•„ìš”í–ˆë‹¤.</li></ol><p>1ë²ˆì˜ ê²½ìš° ì—¬ëŸ¬ ê°€ì§€ë¥¼ ì‹œë„í•˜ë‹¤ condition signalì—ë„ Bi-DilConvë¥¼ ì ìš©í–ˆë”ë‹ˆ ê°‘ìê¸° ì—„ì²­ë‚˜ê²Œ ì˜ë˜ê¸° ì‹œì‘í•˜ì˜€ìŠµë‹ˆë‹¤. Condition signalì˜ receptive fieldë¥¼ Bi-DilConvë¡œ ë„“í˜€ì¤€ ê²ƒì´ íš¨ê³¼ê°€ ìˆì—ˆë‹¤ëŠ” ê²Œ ì €í¬ê°€ ë¶„ì„í•œ ê²°ê³¼ì…ë‹ˆë‹¤.</p><p>2ë²ˆì˜ ê²½ìš° WaveGradì—ì„œ ì œì‹œí–ˆë˜ noise schedule, linear scale ë“±ì˜ ìˆ˜ì¹˜ë¥¼ ìƒë‹¹íˆ ì¡°ì ˆí•˜ê³  í•™ìŠµì„ ì˜¤ë˜ í–ˆë”ë‹ˆ í•´ê²°ë˜ì—ˆìŠµë‹ˆë‹¤. ì•„ì§ diffusion modelì´ ë§ì´ ì—°êµ¬ë˜ì—ˆë˜ ê²ƒì´ ì•„ë‹ˆë‹¤ ë³´ë‹ˆ ì´ëŸ° hyperparameterë“¤ì„ ì§ì ‘ ì—¬ëŸ¬ ë²ˆ í…ŒìŠ¤íŠ¸í•´ë³´ëŠ” ê²ƒë°–ì—ëŠ” ë‹µì´ ì—†ì—ˆìŠµë‹ˆë‹¤.</p><p>3ë²ˆì˜ ê²½ìš° ì¢‹ì€ GPUë¥¼ ì œê³µí•´ì£¼ëŠ” MINDs Labì´ë¼ì„œ A100 ë‘ ëŒ€ë¥¼ ì‚¬ìš©í•´ì„œ í•´ê²°í–ˆìŠµë‹ˆë‹¤.</p><p>í•´ê²° ë°©ë²•ì„ ì—¬ëŸ¬ ê°€ì§€ë¥¼ ì‹œë„í•´ì„œ í•´ê²°í–ˆë‹¤ê³  ì“°ê¸´ í–ˆì§€ë§Œ ì´ ê¸°ê°„ì´ í•œ ë‹¬ ì¢€ ë„˜ì—ˆë˜ ê²ƒ ê°™ìŠµë‹ˆë‹¤. 1ì›”ì— ë³¸ê²©ì ìœ¼ë¡œ ì‹œì‘í•˜ì—¬ êµ¬í˜„ì€ 2ì£¼ì•ˆì— ëë‚¬ëŠ”ë° hyperparameterë§Œ í•œë‹¬ ë„˜ê²Œ ê³ ì³ê°€ë©´ì„œ ì •ë§ ì—¬ëŸ¬ ê°€ì§€ë¥¼ ì‹œë„í•´ë´¤ìŠµë‹ˆë‹¤. í•œ ë‹¬ ë„˜ëŠ” ì‹œë„ ëì— ì¢‹ì€ sampleì„ ë½‘ì•„ë‚´ëŠ” ì •ë„ê°€ ë˜ì–´ 3ì›”ì—ëŠ” ë…¼ë¬¸ ì‘ì„±ì— ë°•ì°¨ë¥¼ ê°€í–ˆë˜ ê²ƒ ê°™ìŠµë‹ˆë‹¤.</p><img class="figCenter_mKJ5" src="/assets/images/sampling-503b47b072ff85dc85742fbd9951fd82.gif" alt="sampling"><p><em>NU-Waveê°€ 8ë²ˆ ë§Œì— samplingí•˜ëŠ” ê³¼ì •</em></p><h3 class="anchor anchorWithStickyNavbar_mojV" id="results">Results<a class="hash-link" href="#results" title="Direct link to heading">â€‹</a></h3><img class="figCenter_mKJ5" src="/assets/images/result-58171d4126d4fe9718d297137c472746.png" alt="result"><p>ì•ì—ì„œ ì†Œê°œí•œ ê²ƒë“¤ê³¼ì˜ ë¹„êµë¥¼ ìœ„í•œ spectrogramì…ë‹ˆë‹¤. ì œì¼ ì™¼ìª½ ì›ë³¸ì— ë¹„í•´ì„œ ê°€ìš´ë° ì„¸ê°œì˜ ê²½ìš° ê³¼í•˜ê²Œ ê¸°ë‘¥ì´ ì„°ê±°ë‚˜, Nyquist frequency ê¸°ì¤€ìœ¼ë¡œ ëŒ€ì¹­ì´ ë˜ê±°ë‚˜ í•˜ëŠ” í˜„ìƒì„ ë³´ì…ë‹ˆë‹¤. í•˜ì§€ë§Œ NU-Waveì˜ ê²½ìš° ìì—°ìŠ¤ëŸ½ê²Œ high frequency ë¶€ë¶„ì„ ìƒì„±í•˜ëŠ” ê²ƒì„ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. </p><table><thead><tr><th>SNR, LSD</th><th>ABX accuracy</th></tr></thead><tbody><tr><td><img loading="lazy" src="/assets/images/objective-2ef1c4d260729597247570d554dac131.png" width="966" height="592"></td><td><img loading="lazy" src="/assets/images/subjective-fb53e1a9c71e1a880977fb76fb92320a.png" width="962" height="338"></td></tr></tbody></table><p>Audio upsampling taskì—ì„œëŠ” í¬ê²Œ 3ê°€ì§€ì˜ metricì„ ì‚¬ìš©í•©ë‹ˆë‹¤. ì›ë³¸ê³¼ downsamplingí•œ ì‹ í˜¸ë¥¼ ë‹¤ì‹œ upsamplingí•œ í›„ ìˆ˜ì¹˜ì ìœ¼ë¡œ ë¹„êµí•˜ëŠ” <em>SNR (signal-to-noise ratio)</em>, <em>LSD (log-spectral distance)</em>ì™€ ì‚¬ëŒì´ ë‹¤ë¥¸ ì¢…ë¥˜ì˜ A, Bì™€ ë‘˜ ì¤‘ í•˜ë‚˜ë¥¼ ë½‘ì€ X ì„¸ê°€ì§€ë¥¼ ë“¤ì–´ë³´ê³  ì–´ëŠê²ƒì¸ì§€ êµ¬ë¶„í•  ìˆ˜ ìˆëŠ” ABX testì˜ ì •í™•ë„ì¸ <em>ABX accuracy</em>ê°€ ìˆìŠµë‹ˆë‹¤. <strong>NU-Waveì˜ ê²½ìš° SNR, LSD, ABX accì—ì„œ 3.0Mì˜ parameterë¡œ ë‹¤ë¥¸ ëª¨ë¸ë“¤ë³´ë‹¤ ë†’ì€ ì„±ëŠ¥ì„ ë³´ì˜€ìŠµë‹ˆë‹¤.</strong> </p><h3 class="anchor anchorWithStickyNavbar_mojV" id="discussion">Discussion<a class="hash-link" href="#discussion" title="Direct link to heading">â€‹</a></h3><p>Downsampling ë°©ì‹ì„ í•œì •ì§€ì–´ ì•„ì§ ì‹¤ì œë¡œ upsamplingì„ í•  ë•ŒëŠ” ë¬¸ì œê°€ ìƒê¸´ë‹¤ëŠ” ì , diffusion modelì˜ íŠ¹ì„±ì¸ì§€ high noiseê°€ ì‚´ì§ ë‚¨ëŠ”ë‹¤ëŠ” ì  ë“± ê°œì„ í•´ì•¼í•  ë¶€ë¶„ì´ ë§ê³  ì›ë˜ì˜ ëª©í‘œì¸ TTSì— ì ìš©í•˜ëŠ” ë¶€ë¶„ë„ ìˆ™ì œë¡œ ë‚¨ì•„ìˆëŠ”ê²ƒ ê°™ìŠµë‹ˆë‹¤. ìì„¸í•œ ë‚´ìš©ì€ <a href="https://arxiv.org/abs/2104.02321" target="_blank" rel="noopener noreferrer">ë…¼ë¬¸</a>ì„ ì°¸ê³ í•´ì£¼ì‹œê³  <a href="https://github.com/mindslab-ai/nuwave" target="_blank" rel="noopener noreferrer">ì½”ë“œ</a>ì— ë§ì€ ìŠ¤íƒ€â­ë¶€íƒë“œë¦½ë‹ˆë‹¤. </p><p>9ì›”ì— INTERSPEECH í•™íšŒì—ì„œ ë´¬ìš”! â€‹</p><h3 class="anchor anchorWithStickyNavbar_mojV" id="references">References<a class="hash-link" href="#references" title="Direct link to heading">â€‹</a></h3><a name="r1"></a><ol><li>V. Kuleshov, S. Z. Enam, and S. Ermon, â€œAudio super resolution using neural networks,â€ in <em>Workshop of International Conference on Learning Representations</em>, 2017. <a href="https://arxiv.org/abs/1708.00853" target="_blank" rel="noopener noreferrer">[arxiv]</a></li></ol><a name="r2"></a><ol start="2"><li>S. Kim and V. Sathe, â€œBandwidth extension on raw audio via generative adversarial networks,â€ <em>arXiv preprint arXiv:1903.09027</em>, 2019. <a href="https://arxiv.org/abs/1903.09027" target="_blank" rel="noopener noreferrer">[arxiv]</a></li></ol><a name="r3"></a><ol start="3"><li>J. Ho, A. Jain, and P. Abbeel, â€œDenoising diffusion probabilistic models,â€ in <em>Advances in Neural Information Processing Systems</em>, 2020, pp. 6840â€“6851. <a href="https://arxiv.org/abs/2006.11239" target="_blank" rel="noopener noreferrer">[arxiv]</a></li></ol><a name="r4"></a><ol start="4"><li>Z. Kong, W. Ping, J. Huang, K. Zhao, and B. Catanzaro, â€œDiffwave: A versatile diffusion model for audio synthesis,â€ in <em>International Conference on Learning Representations</em>, 2021. <a href="https://arxiv.org/abs/2009.09761" target="_blank" rel="noopener noreferrer">[arxiv]</a></li></ol><a name="r5"></a><ol start="5"><li>N. Chen, Y. Zhang, H. Zen, R. J. Weiss, M. Norouzi, and W. Chan, â€œWavegrad: Estimating gradients for waveform generation,â€ in <em>International Conference on Learning Representations</em>, 2021. <a href="https://arxiv.org/abs/2009.00713" target="_blank" rel="noopener noreferrer">[arxiv]</a></li></ol><h3 class="anchor anchorWithStickyNavbar_mojV" id="tldr">TL;DR<a class="hash-link" href="#tldr" title="Direct link to heading">â€‹</a></h3><ol><li><strong>ìµœì´ˆë¡œ 16kHz/24kHzì—ì„œ 48kHzë¡œ upsampling ì„±ê³µ</strong></li><li><strong>ìµœì´ˆë¡œ diffusion modelì„ audio upsamplingì— ì ìš©</strong></li><li><strong>ì ì€ parameter number(3.0M)ìœ¼ë¡œ ë‹¤ë¥¸ ëª¨ë¸ë“¤ì„ ëŠ¥ê°€</strong></li></ol></div><footer class="row docusaurus-mt-lg blogPostDetailsFull_h6_j"><div class="col"><b>Tags:</b><ul class="tags_XVD_ padding--none margin-left--sm"><li class="tag_JSN8"><a class="tag_hD8n tagRegular_D6E_" href="/blog/tags/publication">publication</a></li><li class="tag_JSN8"><a class="tag_hD8n tagRegular_D6E_" href="/blog/tags/paper-review">paper-review</a></li></ul></div></footer></article><div></div><nav class="pagination-nav docusaurus-mt-lg" aria-label="Blog post page navigation"><div class="pagination-nav__item"><a class="pagination-nav__link" href="/blog/acon"><div class="pagination-nav__sublabel">Newer Post</div><div class="pagination-nav__label">Activate or Not: Learning Customized Activation</div></a></div><div class="pagination-nav__item pagination-nav__item--next"></div></nav></main><div class="col col--2"><div class="tableOfContents_cNA8 thin-scrollbar"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#a-diffusion-probabilistic-model-for-neural-audio-upsampling" class="table-of-contents__link toc-highlight">A Diffusion Probabilistic Model for Neural Audio Upsampling</a><ul><li><a href="#audio-upsampling" class="table-of-contents__link toc-highlight">Audio Upsampling</a></li><li><a href="#diffusion-probabilistic-models" class="table-of-contents__link toc-highlight">Diffusion Probabilistic Models</a></li><li><a href="#nu-wave" class="table-of-contents__link toc-highlight">NU-Wave</a></li><li><a href="#results" class="table-of-contents__link toc-highlight">Results</a></li><li><a href="#discussion" class="table-of-contents__link toc-highlight">Discussion</a></li><li><a href="#references" class="table-of-contents__link toc-highlight">References</a></li><li><a href="#tldr" class="table-of-contents__link toc-highlight">TL;DR</a></li></ul></li></ul></div></div></div></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">Contents</div><ul class="footer__items"><li class="footer__item"><a class="footer__link-item" href="/blog">Blog</a></li><li class="footer__item"><a class="footer__link-item" href="/publications">Publications</a></li></ul></div><div class="col footer__col"><div class="footer__title">Community</div><ul class="footer__items"><li class="footer__item"><a href="https://github.com/mindslab-ai" target="_blank" rel="noopener noreferrer" class="footer__link-item"><span>Github<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_I5OW"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></span></a></li></ul></div><div class="col footer__col"><div class="footer__title">More</div><ul class="footer__items"><li class="footer__item"><a class="footer__link-item" href="/careers">Careers</a></li><li class="footer__item"><a class="footer__link-item" href="/blog/tags">Tags</a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright Â© 2022 MINDsLab BRAIN Team. Built with Docusaurus.</div></div></div></footer></div>
<script src="/assets/js/runtime~main.42946587.js"></script>
<script src="/assets/js/main.cca28c97.js"></script>
</body>
</html>