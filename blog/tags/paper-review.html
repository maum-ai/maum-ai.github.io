<!doctype html>
<html lang="en" dir="ltr">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width,initial-scale=1">
<meta name="generator" content="Docusaurus v2.0.0-beta.17">
<link rel="alternate" type="application/rss+xml" href="/blog/rss.xml" title="MINDsLab BRAIN Team RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/blog/atom.xml" title="MINDsLab BRAIN Team Atom Feed">
<link rel="preconnect" href="https://www.google-analytics.com">
<script>window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)},ga.l=+new Date,ga("create","UA-204903244-1","auto"),ga("set","anonymizeIp",!0),ga("send","pageview")</script>
<script async src="https://www.google-analytics.com/analytics.js"></script>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.24/dist/katex.min.css" integrity="sha384-odtC+0UGzzFL/6PNoE8rX/SPcQDXBJ+uRepguP4QkPCm2LBxH3FA3y+fKSiJ+AmM" crossorigin="anonymous"><title data-rh="true">6 posts tagged with &quot;paper-review&quot; | MINDsLab BRAIN Team</title><meta data-rh="true" property="og:title" content="6 posts tagged with &quot;paper-review&quot; | MINDsLab BRAIN Team"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:url" content="https://mindslab-ai.github.io//blog/tags/paper-review"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docusaurus_tag" content="blog_tags_posts"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docsearch:docusaurus_tag" content="blog_tags_posts"><link data-rh="true" rel="icon" href="/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://mindslab-ai.github.io//blog/tags/paper-review"><link data-rh="true" rel="alternate" href="https://mindslab-ai.github.io//blog/tags/paper-review" hreflang="en"><link data-rh="true" rel="alternate" href="https://mindslab-ai.github.io//blog/tags/paper-review" hreflang="x-default"><link rel="stylesheet" href="/assets/css/styles.def04243.css">
<link rel="preload" href="/assets/js/runtime~main.42946587.js" as="script">
<link rel="preload" href="/assets/js/main.d8eebd45.js" as="script">
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){var t=null;try{t=localStorage.getItem("theme")}catch(t){}return t}();t(null!==e?e:"light")}()</script><div id="__docusaurus">
<div role="region"><a href="#" class="skipToContent_ZgBM">Skip to main content</a></div><nav class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Navigation bar toggle" class="navbar__toggle clean-btn" type="button" tabindex="0"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/mindslab_brain.svg" alt="MINDsLab BRAIN Team" class="themedImage_W2Cr themedImage--light_TfLj"><img src="/img/mindslab_brain.svg" alt="MINDsLab BRAIN Team" class="themedImage_W2Cr themedImage--dark_oUvU"></div><b class="navbar__title"></b></a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/blog">Blog</a><a class="navbar__item navbar__link" href="/publications">Publications</a><a class="navbar__item navbar__link" href="/open-source">Open-Source</a></div><div class="navbar__items navbar__items--right"><a class="navbar__item navbar__link" href="/careers">Careers</a><a href="https://github.com/mindslab-ai" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link"><span>GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_I5OW"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></span></a><div class="toggle_S7eR toggle_TdHA toggleDisabled_f9M3"><div class="toggleButton_rCf9" role="button" tabindex="-1"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_v35p"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_nQuB"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></div><input type="checkbox" class="toggleScreenReader_g2nN" aria-label="Switch between dark and light mode (currently light mode)"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div class="main-wrapper blog-wrapper blog-tags-post-list-page"><div class="container margin-vert--lg"><div class="row"><aside class="col col--3"><nav class="sidebar_a9qW thin-scrollbar" aria-label="Blog recent posts navigation"><div class="sidebarItemTitle_uKok margin-bottom--md">All posts</div><ul class="sidebarItemList_Kvuv"><li class="sidebarItem_CF0Q"><a class="sidebarItemLink_miNk" href="/blog/nu-wave2">NU-Wave 2: A General Neural Audio Upsampling Model for Various Sampling Rates</a></li><li class="sidebarItem_CF0Q"><a class="sidebarItemLink_miNk" href="/blog/sane-tts">SANE-TTS: Stable And Natural End-to-End Multilingual Text-to-Speech</a></li><li class="sidebarItem_CF0Q"><a class="sidebarItemLink_miNk" href="/blog/assem-vc">Assem-VC and Assem-Singer:</a></li><li class="sidebarItem_CF0Q"><a class="sidebarItemLink_miNk" href="/blog/ces-2022-review">CES 2022ì— ì°¸ì„í•œ ë§ˆì¸ì¦ˆë©, AI Human</a></li><li class="sidebarItem_CF0Q"><a class="sidebarItemLink_miNk" href="/blog/vits">VITS: Conditional Variational Autoencoder with Adversarial Learning for End-to-End Text-to-Speech</a></li><li class="sidebarItem_CF0Q"><a class="sidebarItemLink_miNk" href="/blog/acon">Activate or Not: Learning Customized Activation</a></li><li class="sidebarItem_CF0Q"><a class="sidebarItemLink_miNk" href="/blog/nu-wave">NU-Wave(Interspeech):</a></li></ul></nav></aside><main class="col col--7" itemscope="" itemtype="http://schema.org/Blog"><header class="margin-bottom--xl"><h1>6 posts tagged with &quot;paper-review&quot;</h1><a href="/blog/tags">View All Tags</a></header><article class="margin-bottom--xl" itemprop="blogPost" itemscope="" itemtype="http://schema.org/BlogPosting"><header><h2 class="blogPostTitle_rzP5" itemprop="headline"><a itemprop="url" href="/blog/nu-wave2">NU-Wave 2: A General Neural Audio Upsampling Model for Various Sampling Rates</a></h2><div class="blogPostData_Zg1s margin-vert--md"><time datetime="2022-10-25T00:00:00.000Z" itemprop="datePublished">October 25, 2022</time> Â· <!-- -->16 min read</div><div class="margin-top--md margin-bottom--sm row"><div class="col col--6 authorCol_FlmR"><div class="avatar margin-bottom--sm"><span class="avatar__photo-link avatar__photo"><a href="https://github.com/Seungwoo0326" target="_blank" rel="noopener noreferrer"><img class="image_o0gy" src="https://github.com/Seungwoo0326.png" alt="Seungu Han"></a></span><div class="avatar__intro" itemprop="author" itemscope="" itemtype="https://schema.org/Person"><div class="avatar__name"><a href="https://github.com/Seungwoo0326" target="_blank" rel="noopener noreferrer" itemprop="url"><span itemprop="name">Seungu Han</span></a></div><small class="avatar__subtitle" itemprop="description">AI Scientist (Audio)</small></div></div></div><div class="col col--6 authorCol_FlmR"><div class="avatar margin-bottom--sm"><span class="avatar__photo-link avatar__photo"><a href="https://github.com/junjun3518" target="_blank" rel="noopener noreferrer"><img class="image_o0gy" src="https://github.com/junjun3518.png" alt="Junhyeok Lee"></a></span><div class="avatar__intro" itemprop="author" itemscope="" itemtype="https://schema.org/Person"><div class="avatar__name"><a href="https://github.com/junjun3518" target="_blank" rel="noopener noreferrer" itemprop="url"><span itemprop="name">Junhyeok Lee</span></a></div><small class="avatar__subtitle" itemprop="description">AI Scientist (Audio, Head)</small></div></div></div></div></header><meta itemprop="image" content="https://mindslab-ai.github.io//img/mindslab_default.png"><div class="markdown" itemprop="articleBody"><p><a href="https://arxiv.org/abs/2206.08545" target="_blank" rel="noopener noreferrer"><img src="https://img.shields.io/badge/arXiv-2206.08545-brightgreen.svg?style=flat-square" alt="arXiv"></a> <a href="https://github.com/mindslab-ai/nuwave2" target="_blank" rel="noopener noreferrer"><img src="https://img.shields.io/github/stars/mindslab-ai/nuwave2?color=yellow&amp;label=NU-Wave2&amp;logo=github&amp;style=flat-square" alt="GitHub Repo stars"></a> <a href="https://mindslab-ai.github.io/nuwave2/" target="_blank" rel="noopener noreferrer"><img src="https://img.shields.io/badge/GitHub.io-audio_samples-blue?logo=Github&amp;style=flat-square" alt="githubio"></a></p><blockquote><p>Seungu Han and Junhyeok Lee. &quot;NU-Wave 2: A General Neural Audio Upsampling Model for Various Sampling Rates&quot; </p><p>INTERSPEECH 2022</p></blockquote><h2 class="anchor anchorWithStickyNavbar_mojV" id="nu-wave-2-a-general-neural-audio-upsampling-model-for-various-sampling-rates">NU-Wave 2: A General Neural Audio Upsampling Model for Various Sampling Rates<a class="hash-link" href="#nu-wave-2-a-general-neural-audio-upsampling-model-for-various-sampling-rates" title="Direct link to heading">â€‹</a></h2><p>ì•ˆë…•í•˜ì„¸ìš”. MINDs Lab Brainì—ì„œ Audio ì—°êµ¬ë¥¼ í•˜ê³  ìˆëŠ” í•œìŠ¹ìš°ì…ë‹ˆë‹¤. ì‘ë…„ì— ì†Œê°œí•´ë“œë ¸ë˜ <a href="https://mindslab-ai.github.io/blog/nu-wave" target="_blank" rel="noopener noreferrer">&quot;NU-Wave: A Diffusion Probabilistic Model for Neural Audio Upsampling&quot;</a><a href="#r1"><sup>[1]</sup></a>ì˜ í›„ì† ì—°êµ¬ì¸ NU-Wave 2ë¥¼ ì†Œê°œí•˜ë ¤í•©ë‹ˆë‹¤. ì•ì„œ <a href="https://github.com/chohyunjae1" target="_blank" rel="noopener noreferrer">í˜„ì¬</a>ë‹˜ì´ ì†Œê°œí•´ì£¼ì‹  <a href="https://mindslab-ai.github.io/blog/sane-tts" target="_blank" rel="noopener noreferrer">&quot;SANE-TTS: Stable And Natural End-to-End Multilingual Text-to-Speech&quot;</a>ì™€ í•¨ê»˜ Interspeech 2022ì— accept ë˜ì–´ 9ì›” 18ì¼ë¶€í„° 22ì¼ê¹Œì§€ ì¸ì²œ ì†¡ë„ì—ì„œ ì—´ë¦° Interspeech 2022ì—ì„œ êµ¬ë‘ ë°œí‘œë¥¼ ë§ˆì¹˜ê³  ì™”ìŠµë‹ˆë‹¤. ì½”ë¡œë‚˜ 19ë¡œ ì¸í•´ ì²˜ìŒìœ¼ë¡œ ëŒ€ë©´ìœ¼ë¡œ ì°¸ì„í•œ êµ­ì œí•™íšŒì´ë©´ì„œë„ ë§ì€ ì‚¬ëŒë“¤ ì•ì—ì„œ ë°œí‘œê¹Œì§€ í•˜ê²Œ ë˜ì–´ ê¸´ì¥ë˜ë©´ì„œë„ ì„¤ë ˆì—ˆëŠ”ë° ë‹¤í–‰íˆ ë¬´ì‚¬íˆ ë°œí‘œë¥¼ ë§ˆì¹˜ê³  ì™”ìŠµë‹ˆë‹¤. ë˜í•œ ë‹¤ë¥¸ ì—°êµ¬ìë¶„ë“¤ì˜ ë°œí‘œë„ ë“£ê³  ì§ˆë¬¸ë„ í•˜ë©° ë§ì€ êµ­ë‚´ì™¸ ì—°êµ¬ìë¶„ë“¤ê³¼ ì†Œí†µí•  ìˆ˜ ìˆëŠ” ì†Œì¤‘í•œ ê²½í—˜ì´ì—ˆìŠµë‹ˆë‹¤. ê·¸ëŸ¼ ì´ì œ ì—°êµ¬ë¥¼ ê°™ì´ ì§„í–‰í•´ì£¼ì‹  <a href="https://github.com/junjun3518" target="_blank" rel="noopener noreferrer">ì¤€í˜</a>ë‹˜ê³¼ ì—°êµ¬ ë° ë°œí‘œì— ë„ì›€ì„ ì£¼ì‹  ëª¨ë“  MINDs Lab Brain íŒ€ì›ë¶„ë“¤ê»˜ ê°ì‚¬ ì¸ì‚¬ ì „í•˜ë©° NU-Wave 2 ì†Œê°œë¥¼ ì‹œì‘í•˜ê² ìŠµë‹ˆë‹¤.</p><h3 class="anchor anchorWithStickyNavbar_mojV" id="motivations">Motivations<a class="hash-link" href="#motivations" title="Direct link to heading">â€‹</a></h3><p>NU-Wave 2ì˜ ë² ì´ìŠ¤ê°€ ë˜ëŠ” NU-WaveëŠ” Diffusion Modelì„ ì ìš©í•´ ìµœì´ˆë¡œ ì˜¤ë””ì˜¤ë¥¼ 48 kHzë¡œ upsampling í•˜ëŠ”ë° ì„±ê³µí•œ ëª¨ë¸ì…ë‹ˆë‹¤. ë” ìì„¸í•œ ë‚´ìš©ì€ <a href="https://mindslab-ai.github.io/blog/nu-wave" target="_blank" rel="noopener noreferrer">NU-Wave(Interspeech):</a>ë¥¼ ì°¸ê³ í•´ì£¼ì„¸ìš”. í•˜ì§€ë§Œ NU-WaveëŠ” ëª‡ ê°€ì§€ ë¬¸ì œë¥¼ ì§€ë‹ˆê³  ìˆëŠ”ë° ì²«ë²ˆì§¸ ë¬¸ì œëŠ” &#x27;ã……, ã…†, ã…Š&#x27;ì™€ ê°™ì€ ì¹˜ì°°ìŒì´ë‚˜ ë§ˆì°°ìŒì€ ê³ ì—­ëŒ€ì—ì„œ ì˜ ìƒì„±í•´ë‚´ëŠ” ë°˜ë©´ì— harmonic ì„±ë¶„ì€ ì˜ ë§Œë“¤ì–´ë‚´ì§€ ëª»í•œë‹¤ëŠ” ì ì…ë‹ˆë‹¤. ë˜í•œ ëª‡ëª‡ ë…¼ë¬¸ë“¤ì—ì„œ NU-Waveê°€ ë‹¤ë¥¸ ë‹¤ì–‘í•œ ìŒì—­ëŒ€ë¥¼ ìƒì„±í•˜ëŠ”ë°ì—ëŠ” ì„±ëŠ¥ì´ ì¢‹ì§€ ì•Šë‹¤ëŠ” ê²°ê³¼ë¥¼ ë³´ì—¬ì¤¬ìŠµë‹ˆë‹¤. ê·¸ë¦¬ê³  ë‘ë²ˆì§¸ ë¬¸ì œëŠ” NU-Waveë§Œì˜ ë¬¸ì œëŠ” ì•„ë‹ˆì§€ë§Œ ì´ì „ ì˜¤ë””ì˜¤ Upsampling ëª¨ë¸ë“¤ì€ inputê³¼ outputì˜ sampling rateê°€ ê³ ì •ë˜ì–´ìˆë‹¤ëŠ” ì ì…ë‹ˆë‹¤. ì´ë ‡ê²Œ input, output sampling rate ìŒì„ ê³ ì •í•´ë²„ë¦¬ë©´ ìƒˆë¡œìš´ ìŒì— ëŒ€í•´ì„œ upsamplingì„ í•˜ê³  ì‹¶ì„ ë•ŒëŠ” ë§¤ë²ˆ ëª¨ë¸ì„ ìƒˆë¡œ í•™ìŠµì‹œì¼œì•¼í•œë‹¤ëŠ” ë¬¸ì œê°€ ìˆìŠµë‹ˆë‹¤. ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ì„œ ì €í¬ëŠ” ì–´ë– í•œ sampling rateì˜ inputì´ ë“¤ì–´ì™€ë„ ì›í•˜ëŠ” í•˜ë‚˜ì˜ sampling rateì˜ ì˜¤ë””ì˜¤ë¡œ upsamplingí•´ì£¼ëŠ” ë¬¸ì œë¥¼ ì˜ë…¼í•˜ê³  ì´ë¥¼ &#x27;General Neural Audio Upsampling&#x27;ì´ë¼ê³  ë¶ˆë €ìŠµë‹ˆë‹¤. ì´ ë¬¸ì œë¥¼ í•´ê²°í•˜ê²Œ ë˜ë©´ ë§Œì•½ ì›í•˜ëŠ” ê²°ê³¼ì˜ sampling rateê°€ 48 kHzë¼ë©´ ëª¨ë¸ì„ í•œ ë²ˆë§Œ í•™ìŠµì‹œì¼œë„ 8 kHzë“  12 kHzë“  í˜¹ì€ 16 kHzë“  ì–´ë–¤ sampling rateì˜ ì˜¤ë””ì˜¤ë„ 48 kHzë¡œ upsamplingí•  ìˆ˜ ìˆê²Œ ë˜ëŠ”ê²ë‹ˆë‹¤.</p></div><footer class="row docusaurus-mt-lg"><div class="col col--9"><b>Tags:</b><ul class="tags_XVD_ padding--none margin-left--sm"><li class="tag_JSN8"><a class="tag_hD8n tagRegular_D6E_" href="/blog/tags/publication">publication</a></li><li class="tag_JSN8"><a class="tag_hD8n tagRegular_D6E_" href="/blog/tags/paper-review">paper-review</a></li></ul></div><div class="col text--right col--3"><a aria-label="Read more about NU-Wave 2: A General Neural Audio Upsampling Model for Various Sampling Rates" href="/blog/nu-wave2"><b>Read More</b></a></div></footer></article><article class="margin-bottom--xl" itemprop="blogPost" itemscope="" itemtype="http://schema.org/BlogPosting"><header><h2 class="blogPostTitle_rzP5" itemprop="headline"><a itemprop="url" href="/blog/sane-tts">SANE-TTS: Stable And Natural End-to-End Multilingual Text-to-Speech</a></h2><div class="blogPostData_Zg1s margin-vert--md"><time datetime="2022-09-02T00:00:00.000Z" itemprop="datePublished">September 2, 2022</time> Â· <!-- -->23 min read</div><div class="margin-top--md margin-bottom--sm row"><div class="col col--6 authorCol_FlmR"><div class="avatar margin-bottom--sm"><span class="avatar__photo-link avatar__photo"><a href="https://github.com/chohyunjae1" target="_blank" rel="noopener noreferrer"><img class="image_o0gy" src="https://github.com/chohyunjae1.png" alt="Hyunjae Cho"></a></span><div class="avatar__intro" itemprop="author" itemscope="" itemtype="https://schema.org/Person"><div class="avatar__name"><a href="https://github.com/chohyunjae1" target="_blank" rel="noopener noreferrer" itemprop="url"><span itemprop="name">Hyunjae Cho</span></a></div><small class="avatar__subtitle" itemprop="description">AI Scientist (Audio)</small></div></div></div><div class="col col--6 authorCol_FlmR"><div class="avatar margin-bottom--sm"><span class="avatar__photo-link avatar__photo"><a href="https://github.com/Wonbin-Jung" target="_blank" rel="noopener noreferrer"><img class="image_o0gy" src="https://github.com/Wonbin-Jung.png" alt="Wonbin Jung"></a></span><div class="avatar__intro" itemprop="author" itemscope="" itemtype="https://schema.org/Person"><div class="avatar__name"><a href="https://github.com/Wonbin-Jung" target="_blank" rel="noopener noreferrer" itemprop="url"><span itemprop="name">Wonbin Jung</span></a></div><small class="avatar__subtitle" itemprop="description">AI Scientist (Audio)</small></div></div></div><div class="col col--6 authorCol_FlmR"><div class="avatar margin-bottom--sm"><span class="avatar__photo-link avatar__photo"><a href="https://github.com/junjun3518" target="_blank" rel="noopener noreferrer"><img class="image_o0gy" src="https://github.com/junjun3518.png" alt="Junhyeok Lee"></a></span><div class="avatar__intro" itemprop="author" itemscope="" itemtype="https://schema.org/Person"><div class="avatar__name"><a href="https://github.com/junjun3518" target="_blank" rel="noopener noreferrer" itemprop="url"><span itemprop="name">Junhyeok Lee</span></a></div><small class="avatar__subtitle" itemprop="description">AI Scientist (Audio, Head)</small></div></div></div><div class="col col--6 authorCol_FlmR"><div class="avatar margin-bottom--sm"><span class="avatar__photo-link avatar__photo"><a href="https://github.com/tonyswoo" target="_blank" rel="noopener noreferrer"><img class="image_o0gy" src="https://github.com/tonyswoo.png" alt="Sang Hoon Woo"></a></span><div class="avatar__intro" itemprop="author" itemscope="" itemtype="https://schema.org/Person"><div class="avatar__name"><a href="https://github.com/tonyswoo" target="_blank" rel="noopener noreferrer" itemprop="url"><span itemprop="name">Sang Hoon Woo</span></a></div><small class="avatar__subtitle" itemprop="description">AI Scientist (Audio)</small></div></div></div></div></header><meta itemprop="image" content="https://mindslab-ai.github.io//img/mindslab_default.png"><div class="markdown" itemprop="articleBody"><p><a href="https://arxiv.org/abs/2206.12132" target="_blank" rel="noopener noreferrer"><img src="https://img.shields.io/badge/arXiv-2206.12132-brightgreen.svg?style=flat-square" alt="arXiv"></a>
<a href="https://mindslab-ai.github.io/sane-tts/" target="_blank" rel="noopener noreferrer"><img src="https://img.shields.io/static/v1?message=Audio%20Samples&amp;logo=Github&amp;labelColor=grey&amp;color=blue&amp;logoColor=white&amp;label=%20&amp;style=flat-square" alt="githubio"></a></p><blockquote><p>Hyunjae Cho, Wonbin Jung, Junhyeok Lee, and Sang Hoon Woo. &quot;SANE-TTS: Stable And Natural End-to-End Multilingual Text-to-Speech.&quot; </p><p>INTERSPEECH 2022</p></blockquote><h2 class="anchor anchorWithStickyNavbar_mojV" id="sane-tts-stable-and-natural-end-to-end-multilingual-text-to-speech">SANE-TTS: Stable And Natural End-to-End Multilingual Text-to-Speech<a class="hash-link" href="#sane-tts-stable-and-natural-end-to-end-multilingual-text-to-speech" title="Direct link to heading">â€‹</a></h2><p>ì•ˆë…•í•˜ì„¸ìš”. MINDsLab BrainíŒ€ì—ì„œ ìŒì„±í•©ì„± ì—°êµ¬ë¥¼ í•˜ê³  ìˆëŠ” ì¡°í˜„ì¬ì…ë‹ˆë‹¤.</p><p>ì˜¤ëŠ˜ì€ ì €í¬ BrainíŒ€ì—ì„œ ê°™ì´ ì“´ SANE-TTS paperê°€ <a href="https://www.interspeech2022.org" target="_blank" rel="noopener noreferrer">INTERSPEECH 2022</a>ì— acceptë˜ì—ˆë‹¤ëŠ” ì¢‹ì€ ì†Œì‹ê³¼ í•¨ê»˜ ì†Œê°œí•´ë“œë¦¬ëŠ” ì‹œê°„ì„ ê°€ì§€ë ¤ í•©ë‹ˆë‹¤.</p><h3 class="anchor anchorWithStickyNavbar_mojV" id="contributions">Contributions<a class="hash-link" href="#contributions" title="Direct link to heading">â€‹</a></h3><ul><li>SANE-TTSëŠ” ì•ˆì •ì ì´ê³  ìì—°ìŠ¤ëŸ¬ìš´ ë‹¤êµ­ì–´ ìŒì„±ì„ í•©ì„±í•©ë‹ˆë‹¤.</li><li>ì´ ë…¼ë¬¸ì—ì„œ ì œì•ˆí•œ <em>speaker regularization loss</em>ëŠ” ê¸°ì¡´ ë‹¤êµ­ì–´ TTS ëª¨ë¸ì—ì„œë„ ì‚¬ìš©ëœ ë°©ë²•ì¸ domain adversarial trainingê³¼ ë¹„ìŠ·í•œ ìˆ˜ì¤€ì˜ í€„ë¦¬í‹° í–¥ìƒì„ ì´ëŒì–´ëƒ…ë‹ˆë‹¤.</li></ul></div><footer class="row docusaurus-mt-lg"><div class="col col--9"><b>Tags:</b><ul class="tags_XVD_ padding--none margin-left--sm"><li class="tag_JSN8"><a class="tag_hD8n tagRegular_D6E_" href="/blog/tags/publication">publication</a></li><li class="tag_JSN8"><a class="tag_hD8n tagRegular_D6E_" href="/blog/tags/paper-review">paper-review</a></li></ul></div><div class="col text--right col--3"><a aria-label="Read more about SANE-TTS: Stable And Natural End-to-End Multilingual Text-to-Speech" href="/blog/sane-tts"><b>Read More</b></a></div></footer></article><article class="margin-bottom--xl" itemprop="blogPost" itemscope="" itemtype="http://schema.org/BlogPosting"><header><h2 class="blogPostTitle_rzP5" itemprop="headline"><a itemprop="url" href="/blog/assem-vc">Assem-VC and Assem-Singer:</a></h2><div class="blogPostData_Zg1s margin-vert--md"><time datetime="2022-08-19T00:00:00.000Z" itemprop="datePublished">August 19, 2022</time> Â· <!-- -->14 min read</div><div class="margin-top--md margin-bottom--sm row"><div class="col col--6 authorCol_FlmR"><div class="avatar margin-bottom--sm"><span class="avatar__photo-link avatar__photo"><a href="https://github.com/wookladin" target="_blank" rel="noopener noreferrer"><img class="image_o0gy" src="https://github.com/wookladin.png" alt="Kang-wook Kim"></a></span><div class="avatar__intro" itemprop="author" itemscope="" itemtype="https://schema.org/Person"><div class="avatar__name"><a href="https://github.com/wookladin" target="_blank" rel="noopener noreferrer" itemprop="url"><span itemprop="name">Kang-wook Kim</span></a></div><small class="avatar__subtitle" itemprop="description">AI Scientist (Audio)</small></div></div></div><div class="col col--6 authorCol_FlmR"><div class="avatar margin-bottom--sm"><span class="avatar__photo-link avatar__photo"><a href="https://github.com/junjun3518" target="_blank" rel="noopener noreferrer"><img class="image_o0gy" src="https://github.com/junjun3518.png" alt="Junhyeok Lee"></a></span><div class="avatar__intro" itemprop="author" itemscope="" itemtype="https://schema.org/Person"><div class="avatar__name"><a href="https://github.com/junjun3518" target="_blank" rel="noopener noreferrer" itemprop="url"><span itemprop="name">Junhyeok Lee</span></a></div><small class="avatar__subtitle" itemprop="description">AI Scientist (Audio, Head)</small></div></div></div></div></header><meta itemprop="image" content="https://mindslab-ai.github.io//img/mindslab_default.png"><div class="markdown" itemprop="articleBody"><p>Assem-VC</p><p><a href="https://arxiv.org/abs/2104.00931" target="_blank" rel="noopener noreferrer"><img src="https://img.shields.io/badge/arXiv-2104.00931-brightgreen.svg?style=flat-square" alt="arXiv"></a>
<a href="https://mindslab-ai.github.io/assem-vc/index.html" target="_blank" rel="noopener noreferrer"><img src="https://img.shields.io/static/v1?message=Audio%20Samples&amp;logo=Github&amp;labelColor=grey&amp;color=lightgrey&amp;logoColor=white&amp;label=%20&amp;style=flat-square" alt="githubio"></a>
<a href="https://github.com/mindslab-ai/assem-vc" target="_blank" rel="noopener noreferrer"><img src="https://img.shields.io/static/v1?message=Official%20Repo&amp;logo=Github&amp;labelColor=grey&amp;color=blue&amp;logoColor=white&amp;label=%20&amp;style=flat-square" alt="githubio"></a></p><p>Assem-Singer</p><p><a href="https://arxiv.org/abs/2110.12676" target="_blank" rel="noopener noreferrer"><img src="https://img.shields.io/badge/arXiv-2110.12676-brightgreen.svg?style=flat-square" alt="arXiv"></a>
<a href="https://mindslab-ai.github.io/assem-vc/singer/index.html" target="_blank" rel="noopener noreferrer"><img src="https://img.shields.io/static/v1?message=Audio%20Samples&amp;logo=Github&amp;labelColor=grey&amp;color=lightgrey&amp;logoColor=white&amp;label=%20&amp;style=flat-square" alt="githubio"></a></p><p>ì•ˆë…•í•˜ì„¸ìš”! MINDsLab Brainì˜ ìŒì„±í•©ì„± ì—°êµ¬ë¥¼ ë‹´ë‹¹í•œ <a href="https://kwkim.me" target="_blank" rel="noopener noreferrer">ê¹€ê°•ìš±</a>ì…ë‹ˆë‹¤.</p><p>ì˜¤ëŠ˜ì€ ì €í¬ Brain íŒ€ì—ì„œ ì¶œíŒí•œ ë…¼ë¬¸ì¸ <strong>Assem-VC<a href="#r1">[1]</a>ì™€ Assem-Singer<a href="#r2">[2]</a></strong>ë¥¼ ì†Œê°œë“œë¦¬ëŠ” ì‹œê°„ì„ ê°€ì§€ë ¤ í•©ë‹ˆë‹¤!</p></div><footer class="row docusaurus-mt-lg"><div class="col col--9"><b>Tags:</b><ul class="tags_XVD_ padding--none margin-left--sm"><li class="tag_JSN8"><a class="tag_hD8n tagRegular_D6E_" href="/blog/tags/publication">publication</a></li><li class="tag_JSN8"><a class="tag_hD8n tagRegular_D6E_" href="/blog/tags/paper-review">paper-review</a></li></ul></div><div class="col text--right col--3"><a aria-label="Read more about Assem-VC and Assem-Singer:" href="/blog/assem-vc"><b>Read More</b></a></div></footer></article><article class="margin-bottom--xl" itemprop="blogPost" itemscope="" itemtype="http://schema.org/BlogPosting"><header><h2 class="blogPostTitle_rzP5" itemprop="headline"><a itemprop="url" href="/blog/vits">VITS: Conditional Variational Autoencoder with Adversarial Learning for End-to-End Text-to-Speech</a></h2><div class="blogPostData_Zg1s margin-vert--md"><time datetime="2021-10-19T00:00:00.000Z" itemprop="datePublished">October 19, 2021</time> Â· <!-- -->32 min read</div><div class="margin-top--md margin-bottom--sm row"><div class="col col--6 authorCol_FlmR"><div class="avatar margin-bottom--sm"><span class="avatar__photo-link avatar__photo"><a href="https://github.com/Wonbin-Jung" target="_blank" rel="noopener noreferrer"><img class="image_o0gy" src="https://github.com/Wonbin-Jung.png" alt="Wonbin Jung"></a></span><div class="avatar__intro" itemprop="author" itemscope="" itemtype="https://schema.org/Person"><div class="avatar__name"><a href="https://github.com/Wonbin-Jung" target="_blank" rel="noopener noreferrer" itemprop="url"><span itemprop="name">Wonbin Jung</span></a></div><small class="avatar__subtitle" itemprop="description">AI Scientist (Audio)</small></div></div></div></div></header><meta itemprop="image" content="https://mindslab-ai.github.io//img/mindslab_default.png"><div class="markdown" itemprop="articleBody"><p><a href="https://arxiv.org/abs/2106.06103" target="_blank" rel="noopener noreferrer"><img src="https://img.shields.io/badge/arXiv-2106.06103-brightgreen.svg?style=flat-square" alt="arXiv"></a>
<a href="https://github.com/jaywalnut310/vits" target="_blank" rel="noopener noreferrer"><img src="https://img.shields.io/static/v1?message=Official%20Repo&amp;logo=Github&amp;labelColor=grey&amp;color=blue&amp;logoColor=white&amp;label=%20&amp;style=flat-square" alt="githubio"></a>
<a href="https://jaywalnut310.github.io/vits-demo/index.html" target="_blank" rel="noopener noreferrer"><img src="https://img.shields.io/static/v1?message=Audio%20Samples&amp;logo=Github&amp;labelColor=grey&amp;color=lightgrey&amp;logoColor=white&amp;label=%20&amp;style=flat-square" alt="githubio"></a></p><blockquote><p>Kim, Jaehyeon, Jungil Kong, and Juhee Son. &quot;Conditional Variational Autoencoder with Adversarial Learning for End-to-End Text-to-Speech.&quot; </p><p>International Conference on Machine Learning (ICML) 2021</p></blockquote><h2 class="anchor anchorWithStickyNavbar_mojV" id="variational-inference-with-adversarial-learning-for-end-to-end-text-to-speech">Variational Inference with adversarial learning for end-to-end Text-to-Speech<a class="hash-link" href="#variational-inference-with-adversarial-learning-for-end-to-end-text-to-speech" title="Direct link to heading">â€‹</a></h2><p>ì•ˆë…•í•˜ì„¸ìš”! MINDs Lab Brainì—ì„œ text-to-speech (TTS) ì—°êµ¬ë¥¼ í•˜ê³  ìˆëŠ” ì •ì›ë¹ˆì…ë‹ˆë‹¤. ì˜¤ëŠ˜ì€ ì§€ë‚œ ì—¬ë¦„ì— ë°œí‘œëœ end-to-end TTSì¸ Variational Inference with adversarial learning for end-to-end Text-to-Speech, <strong>VITS</strong>ì— ëŒ€í•´ ì†Œê°œí•˜ê³ , ë¦¬ë·°ë¥¼ ì§„í–‰í•˜ê³ ì í•©ë‹ˆë‹¤.</p><h3 class="anchor anchorWithStickyNavbar_mojV" id="contributions">Contributions<a class="hash-link" href="#contributions" title="Direct link to heading">â€‹</a></h3><ul><li>1ë‹¨ê³„ í•©ì„± ë° ë³‘ë ¬ íŠ¸ë ˆì´ë‹ì´ ê°€ëŠ¥í•˜ë©° ì„±ëŠ¥ì´ ê¸°ì¡´ ëª¨ë¸ì— ê²¬ì¤„ ìˆ˜ ìˆëŠ” end-to-end TTSë¥¼ ì œì•ˆí–ˆìŠµë‹ˆë‹¤.</li><li>Variational Auto-Encoder (VAE)ì˜ êµ¬ì¡°ë¥¼ ì ìš©í•˜ì—¬ 2ë‹¨ê³„ í•©ì„±ì„ í•˜ë‚˜ë¡œ ì—°ê²°ì‹œì¼°ìŠµë‹ˆë‹¤.</li><li>Variational inferenceì— normalizing flowì™€ generative adversarial network (GAN)ì˜ adversarial trainingì„ ê²°í•©ì‹œì¼œ í‘œí˜„ë ¥ì„ ë†’ì˜€ìŠµë‹ˆë‹¤.</li><li>Stochastic duration predictor (SDP)ë¥¼ ì‚¬ìš©í•˜ì—¬ ëœë¤í•˜ê²Œ ìŒì„±ì˜ ê¸¸ì´ë¥¼ ì˜ˆì¸¡í•˜ë¯€ë¡œ ìŒì„±ì˜ ë‹¤ì–‘ì„±ì´ í–¥ìƒë˜ì—ˆìŠµë‹ˆë‹¤.</li></ul></div><footer class="row docusaurus-mt-lg"><div class="col col--9"><b>Tags:</b><ul class="tags_XVD_ padding--none margin-left--sm"><li class="tag_JSN8"><a class="tag_hD8n tagRegular_D6E_" href="/blog/tags/paper-review">paper-review</a></li></ul></div><div class="col text--right col--3"><a aria-label="Read more about VITS: Conditional Variational Autoencoder with Adversarial Learning for End-to-End Text-to-Speech" href="/blog/vits"><b>Read More</b></a></div></footer></article><article class="margin-bottom--xl" itemprop="blogPost" itemscope="" itemtype="http://schema.org/BlogPosting"><header><h2 class="blogPostTitle_rzP5" itemprop="headline"><a itemprop="url" href="/blog/acon">Activate or Not: Learning Customized Activation</a></h2><div class="blogPostData_Zg1s margin-vert--md"><time datetime="2021-07-19T00:00:00.000Z" itemprop="datePublished">July 19, 2021</time> Â· <!-- -->15 min read</div><div class="margin-top--md margin-bottom--sm row"><div class="col col--6 authorCol_FlmR"><div class="avatar margin-bottom--sm"><span class="avatar__photo-link avatar__photo"><a href="https://github.com/deepkyu" target="_blank" rel="noopener noreferrer"><img class="image_o0gy" src="https://github.com/deepkyu.png" alt="Hyoung-Kyu Song"></a></span><div class="avatar__intro" itemprop="author" itemscope="" itemtype="https://schema.org/Person"><div class="avatar__name"><a href="https://github.com/deepkyu" target="_blank" rel="noopener noreferrer" itemprop="url"><span itemprop="name">Hyoung-Kyu Song</span></a></div><small class="avatar__subtitle" itemprop="description">AI Scientist (Vision, Head)</small></div></div></div></div></header><meta itemprop="image" content="https://mindslab-ai.github.io//img/mindslab_default.png"><div class="markdown" itemprop="articleBody"><p><a href="https://arxiv.org/abs/2009.04759" target="_blank" rel="noopener noreferrer"><img src="https://img.shields.io/badge/arXiv-2009.04759-brightgreen.svg?style=flat-square" alt="arXiv"></a>
<a href="https://github.com/nmaac/acon" target="_blank" rel="noopener noreferrer"><img src="https://img.shields.io/static/v1?message=Official%20Repo&amp;logo=Github&amp;labelColor=grey&amp;color=blue&amp;logoColor=white&amp;label=%20&amp;style=flat-square" alt="githubio"></a></p><blockquote><p>Ma, Ningning, et al. &quot;Activate or Not: Learning Customized Activation.&quot;<br>
<!-- -->Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2021.</p></blockquote><h2 class="anchor anchorWithStickyNavbar_mojV" id="ë¨¼ì €-ì•Œë©´-ì¢‹ì€-ê²ƒë“¤">ë¨¼ì € ì•Œë©´ ì¢‹ì€ ê²ƒë“¤<a class="hash-link" href="#ë¨¼ì €-ì•Œë©´-ì¢‹ì€-ê²ƒë“¤" title="Direct link to heading">â€‹</a></h2><h3 class="anchor anchorWithStickyNavbar_mojV" id="swish-activation-function-sup1sup">Swish Activation Function <a href="#r1"><sup>[1]</sup></a><a class="hash-link" href="#swish-activation-function-sup1sup" title="Direct link to heading">â€‹</a></h3><div class="math math-display"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi mathvariant="normal">swish</mi><mo>â¡</mo><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>:</mo><mo>=</mo><mi>x</mi><mo>Ã—</mo><mi>Ïƒ</mi><mo stretchy="false">(</mo><mi>Î²</mi><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><mfrac><mi>x</mi><mrow><mn>1</mn><mo>+</mo><msup><mi>e</mi><mrow><mo>âˆ’</mo><mi>Î²</mi><mi>x</mi></mrow></msup></mrow></mfrac></mrow><annotation encoding="application/x-tex">\operatorname{swish}(x):=x \times \sigma(\beta x)=\frac{x}{1+e^{-\beta x}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mop"><span class="mord mathrm">swish</span></span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">:=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.6667em;vertical-align:-0.0833em"></span><span class="mord mathnormal">x</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">Ã—</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathnormal" style="margin-right:0.03588em">Ïƒ</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.05278em">Î²</span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1.8769em;vertical-align:-0.7693em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.1076em"><span style="top:-2.314em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord">1</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7751em"><span style="top:-2.989em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">âˆ’</span><span class="mord mathnormal mtight" style="margin-right:0.05278em">Î²</span><span class="mord mathnormal mtight">x</span></span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:0.04em"></span></span><span style="top:-3.677em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord mathnormal">x</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.7693em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></div><img class="figCenter_mKJ5" src="/assets/images/figure1_swish-c594f427f7c7dacfa81c1f6d97e10eb5.png" alt="figure1_swish"><ul><li>Linear Functionê³¼ ReLU ì‚¬ì´ì—ì„œì˜ non-linearly interpolated activationì„ ë³´ì—¬ì¤ë‹ˆë‹¤.<ul><li><span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Î²</mi><mo>=</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">Î² = 0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em"></span><span class="mord mathnormal" style="margin-right:0.05278em">Î²</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">0</span></span></span></span></span> ì¼ ê²½ìš°, Linear function <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><mi>x</mi><mi mathvariant="normal">/</mi><mn>2</mn></mrow><annotation encoding="application/x-tex">f(x) = x/2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathnormal" style="margin-right:0.10764em">f</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathnormal">x</span><span class="mord">/2</span></span></span></span></span> ì²˜ëŸ¼ ì‘ìš©í•˜ê²Œ ë©ë‹ˆë‹¤.</li><li>ë°˜ëŒ€ë¡œ <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Î²</mi><mo>â†’</mo><mi mathvariant="normal">âˆ</mi></mrow><annotation encoding="application/x-tex">Î² â†’ âˆ</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em"></span><span class="mord mathnormal" style="margin-right:0.05278em">Î²</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">â†’</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord">âˆ</span></span></span></span></span>ì¼ ê²½ìš°, Sigmoidì— í•´ë‹¹í•˜ëŠ” ë¶€ë¶„ì´ 0-1 activationì²˜ëŸ¼ ì‘ìš©í•˜ê²Œ ë˜ì–´, Swishê°€ ReLUì²˜ëŸ¼ ì‘ìš©í•˜ê²Œ ë©ë‹ˆë‹¤.</li><li><span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Î²</mi><mo>=</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">Î² = 1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em"></span><span class="mord mathnormal" style="margin-right:0.05278em">Î²</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">1</span></span></span></span></span>ì¼ ê²½ìš°, ê°•í™”í•™ìŠµì—ì„œ ì‚¬ìš©ë˜ëŠ” Sigmoid-weighted Linear Unit (SiL) functionì²˜ëŸ¼ ì‘ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.</li><li><span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Î²</mi></mrow><annotation encoding="application/x-tex">Î²</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em"></span><span class="mord mathnormal" style="margin-right:0.05278em">Î²</span></span></span></span></span>ëŠ” ìœ„ì—ì„œ ë³´ì‹  ê²ƒì²˜ëŸ¼ ì–´ë–¤ ìƒìˆ˜ì¼ ìˆ˜ë„ ìˆê³ , ëª¨ë¸ì— ë”°ë¼ì„œëŠ” í›ˆë ¨ ê°€ëŠ¥í•œ íŒŒë¼ë¯¸í„°ê°€ ë  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤.</li></ul></li><li>ë¸Œë ˆì¸íŒ€ AI Scientistë¶„ë“¤ì´ ìì£¼ ì‚¬ìš©í•˜ì‹œëŠ” Activation Functionì´ê¸°ë„ í•˜ì£  ğŸ™‚</li><li>Generative Modelì—ì„œë„ ReLU ëŒ€ì‹  ì‚¬ìš©í•˜ëŠ” ê²½ìš°ê°€ ë§ì´ ìˆìŠµë‹ˆë‹¤.</li><li>ìµœê·¼ì—ëŠ” Implicit Representation Network ìƒì—ì„œë„ Swishê°€ ë‹¤ì‹œê¸ˆ ì£¼ëª©ì„ ë°›ê³  ìˆìŠµë‹ˆë‹¤.<ul><li>SIRENì—ì„œ ì–¸ê¸‰í•˜ëŠ” periodic function activation (Sine í•¨ìˆ˜ ë“±) ë³´ë‹¤ Swishê°€ ë” ë‚˜ì€ ì„±ëŠ¥ì„ ë³´ì´ëŠ” Taskê°€ ìˆìŠµë‹ˆë‹¤.</li></ul></li></ul></div><footer class="row docusaurus-mt-lg"><div class="col col--9"><b>Tags:</b><ul class="tags_XVD_ padding--none margin-left--sm"><li class="tag_JSN8"><a class="tag_hD8n tagRegular_D6E_" href="/blog/tags/paper-review">paper-review</a></li></ul></div><div class="col text--right col--3"><a aria-label="Read more about Activate or Not: Learning Customized Activation" href="/blog/acon"><b>Read More</b></a></div></footer></article><article class="margin-bottom--xl" itemprop="blogPost" itemscope="" itemtype="http://schema.org/BlogPosting"><header><h2 class="blogPostTitle_rzP5" itemprop="headline"><a itemprop="url" href="/blog/nu-wave">NU-Wave(Interspeech):</a></h2><div class="blogPostData_Zg1s margin-vert--md"><time datetime="2021-07-14T00:00:00.000Z" itemprop="datePublished">July 14, 2021</time> Â· <!-- -->16 min read</div><div class="margin-top--md margin-bottom--sm row"><div class="col col--6 authorCol_FlmR"><div class="avatar margin-bottom--sm"><span class="avatar__photo-link avatar__photo"><a href="https://github.com/junjun3518" target="_blank" rel="noopener noreferrer"><img class="image_o0gy" src="https://github.com/junjun3518.png" alt="Junhyeok Lee"></a></span><div class="avatar__intro" itemprop="author" itemscope="" itemtype="https://schema.org/Person"><div class="avatar__name"><a href="https://github.com/junjun3518" target="_blank" rel="noopener noreferrer" itemprop="url"><span itemprop="name">Junhyeok Lee</span></a></div><small class="avatar__subtitle" itemprop="description">AI Scientist (Audio, Head)</small></div></div></div><div class="col col--6 authorCol_FlmR"><div class="avatar margin-bottom--sm"><span class="avatar__photo-link avatar__photo"><a href="https://github.com/Seungwoo0326" target="_blank" rel="noopener noreferrer"><img class="image_o0gy" src="https://github.com/Seungwoo0326.png" alt="Seungu Han"></a></span><div class="avatar__intro" itemprop="author" itemscope="" itemtype="https://schema.org/Person"><div class="avatar__name"><a href="https://github.com/Seungwoo0326" target="_blank" rel="noopener noreferrer" itemprop="url"><span itemprop="name">Seungu Han</span></a></div><small class="avatar__subtitle" itemprop="description">AI Scientist (Audio)</small></div></div></div></div></header><meta itemprop="image" content="https://mindslab-ai.github.io//img/mindslab_default.png"><div class="markdown" itemprop="articleBody"><p><a href="https://arxiv.org/abs/2104.02321" target="_blank" rel="noopener noreferrer"><img src="https://img.shields.io/badge/arXiv-2104.02321-brightgreen.svg?style=flat-square" alt="arXiv"></a> <a href="https://github.com/mindslab-ai/nuwave" target="_blank" rel="noopener noreferrer"><img src="https://img.shields.io/github/stars/mindslab-ai/nuwave?color=yellow&amp;label=NU-Wave&amp;logo=github&amp;style=flat-square" alt="GitHub Repo stars"></a> <a href="https://mindslab-ai.github.io/nuwave/" target="_blank" rel="noopener noreferrer"><img src="https://img.shields.io/badge/GitHub.io-audio_samples-blue?logo=Github&amp;style=flat-square" alt="githubio"></a></p><h2 class="anchor anchorWithStickyNavbar_mojV" id="a-diffusion-probabilistic-model-for-neural-audio-upsampling">A Diffusion Probabilistic Model for Neural Audio Upsampling<a class="hash-link" href="#a-diffusion-probabilistic-model-for-neural-audio-upsampling" title="Direct link to heading">â€‹</a></h2><p>ì•ˆë…•í•˜ì„¸ìš” MINDs Lab Brainì—ì„œ Audioì™€ Speech ì—°êµ¬ë¥¼ í•˜ê³  ìˆëŠ” <a href="https://github.com/junjun3518" target="_blank" rel="noopener noreferrer">ì´ì¤€í˜</a>ì…ë‹ˆë‹¤. Audio domainì˜ ë”¥ëŸ¬ë‹ ì—°êµ¬ëŠ” ëŒ€ë¶€ë¶„ <em>Sampling Rate</em> 16kHzì¸ ê²½ìš°ì— ëŒ€í•´ì„œ ì§„í–‰ë˜ì—ˆìŠµë‹ˆë‹¤. ìƒì„±ëª¨ë¸ (TTS) ê°™ì€ ê²½ìš° 22.05kHzì¸ ê²½ìš°ë„ ìˆì—ˆì§€ë§Œ ìŒì•…ì´ë‚˜ ì˜í™” ìª½ì—ì„œ ë§ì´ ì“°ì´ëŠ” 44.1kHzë‚˜ 48kHzì— ë¹„í•´ì„œëŠ” ì ˆë°˜ë°–ì— ì•ˆ ë˜ëŠ” sampling rateì´ì—ˆê¸° ë•Œë¬¸ì— high sampling rate TTSì— ëŒ€í•œ ìˆ˜ìš”ê°€ ê¾¸ì¤€íˆ ìˆì—ˆìŠµë‹ˆë‹¤. ì €í¬ê°€ ê°œë°œí•œ TTSì— ëŒ€í•´ì„œ ë” ë†’ì€ í€„ë¦¬í‹°ë¡œ ì„œë¹„ìŠ¤ë¥¼ ì œê³µí•˜ê¸° ìœ„í•´ì„œ <em>Neural Audio Upsampling</em>ì— ëŒ€í•œ ì—°êµ¬ë¥¼ ì§„í–‰í•˜ê²Œ ë˜ì—ˆìŠµë‹ˆë‹¤. 48kHzë¼ëŠ” ë†’ì€ sampling rateë¥¼ ëª©í‘œë¡œ í•˜ëŠ” ì—°êµ¬ë¥¼ ì§„í–‰í•˜ë‹¤ ë³´ë‹ˆ ìì—°ìŠ¤ëŸ½ê²Œ ìµœê·¼ì— í•«í•œ ìƒì„±ëª¨ë¸ì¸ <em>diffusion model</em>ì„ ì ìš©í•˜ê²Œ ë˜ì—ˆê³  <strong>ìµœì´ˆë¡œ 48kHzë¥¼ targetìœ¼ë¡œ upsampling í•˜ëŠ”ë° ì„±ê³µ</strong>í•˜ì˜€ìŠµë‹ˆë‹¤. ì´ë ‡ê²Œ ì§„í–‰í•œ ì—°êµ¬ë¡œ <a href="https://github.com/Seungwoo0326" target="_blank" rel="noopener noreferrer">ìŠ¹ìš°</a>ë‹˜ê³¼ ê°™ì´ ì“´ paperê°€ <strong>ì„¸ê³„ ìµœê³ ì˜ ìŒì„±ì‹ í˜¸ì²˜ë¦¬í•™íšŒì¸ <a href="https://www.interspeech2021.org" target="_blank" rel="noopener noreferrer">INTERSPEECH 2021</a>ì— Accept</strong>ğŸ‰ ë˜ì–´ ì†Œê°œí•´ ë“œë¦¬ê³ ì í•©ë‹ˆë‹¤!</p></div><footer class="row docusaurus-mt-lg"><div class="col col--9"><b>Tags:</b><ul class="tags_XVD_ padding--none margin-left--sm"><li class="tag_JSN8"><a class="tag_hD8n tagRegular_D6E_" href="/blog/tags/publication">publication</a></li><li class="tag_JSN8"><a class="tag_hD8n tagRegular_D6E_" href="/blog/tags/paper-review">paper-review</a></li></ul></div><div class="col text--right col--3"><a aria-label="Read more about NU-Wave(Interspeech):" href="/blog/nu-wave"><b>Read More</b></a></div></footer></article><nav class="pagination-nav" aria-label="Blog list page navigation"><div class="pagination-nav__item"></div><div class="pagination-nav__item pagination-nav__item--next"></div></nav></main></div></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">Contents</div><ul class="footer__items"><li class="footer__item"><a class="footer__link-item" href="/blog">Blog</a></li><li class="footer__item"><a class="footer__link-item" href="/publications">Publications</a></li></ul></div><div class="col footer__col"><div class="footer__title">Community</div><ul class="footer__items"><li class="footer__item"><a href="https://github.com/mindslab-ai" target="_blank" rel="noopener noreferrer" class="footer__link-item"><span>Github<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_I5OW"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></span></a></li></ul></div><div class="col footer__col"><div class="footer__title">More</div><ul class="footer__items"><li class="footer__item"><a class="footer__link-item" href="/careers">Careers</a></li><li class="footer__item"><a class="footer__link-item" href="/blog/tags">Tags</a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright Â© 2023 MINDsLab BRAIN Team. Built with Docusaurus.</div></div></div></footer></div>
<script src="/assets/js/runtime~main.42946587.js"></script>
<script src="/assets/js/main.d8eebd45.js"></script>
</body>
</html>